---
title: "ANOVA Walkthrough"
author: "Hayley Zorkic"
date: "2022-01-27"
slug: []
categories: []
tags: []
draft: no
description: "Step-by-step guide to referenece when running a one-way ANOVA"
image: /img/portfolio/anova_main.jpeg
showonlyimage: no
---

![](/img/portfolio/anova_main.jpeg)

### What is ANOVA?

ANOVA (Analysis of Variance) falls under a category of techniques called *inferential statistics* which allow you to test hypotheses or assess if Analysis of Variance your sample is generalizablbe to a broader population. A one-way ANOVA is a technique that extends the independent two-sample t-test to multiple groups, enabling users to determine if there is a statistically significant difference between group population means. 

### Why ANOVA?

Say, for example, we want to find out which pre-workout snack lead to different mean mile times. For this example, we will be testing carrots, snickers, and bannans. Because there are millions of people around the world who workout everyday, it would be almost impossible to asses the effect of their pre-workout snack on their mile time, so we select a *random sample* of individuals who work out and give each of them one of the three pre-workout snacks, and record their mile time after they eat their respective snack. 

Due to natural variation between people, the mean mile time between each group will vary, but one-way ANOVAs allow us to determine if the difference between group means is statistically significant. 

---

### ANOVA Assumptions 

In order for the ANOVA results to be valid, we need to meet the following assumptiosn. 

**1. Random Sample, Independent observations, and Independent sample groups**

- These are ensured by experiment design

**2. Normal distribution in each group OR large sample in each group**

- Eyeball a histogram/boxplot/qqplot of the response in each groups
    
```{R}
#make this example reproducible
set.seed(0)

#create data frame
data <- data.frame(snack = rep(c("A", "B", "C"), each = 30),
                   mile_time = c(runif(30, 0, 3),
                                   runif(30, 0, 5),
                                   runif(30, 1, 7)))

#fit the one-way ANOVA model
model <- aov(mile_time ~ snack, data = data)

#create histogram
hist(data$mile_time)
```
```{R}
#create Q-Q plot to compare this dataset to a theoretical normal distribution 
qqnorm(model$residuals)

#add straight diagonal line to plot
qqline(model$residuals)
```
- Run a formal statistical analysis on the residuals such as the Shapiro-Wilk, Kolmogorov-Smironov, Jarque-Barre, or D’Agostino-Pearson tests. 
    
```{R}
#Conduct Shapiro-Wilk Test for normality 
shapiro.test(data$mile_time)
```

**3. Equal variance in each group**

- Eeyball boxplot or run bartlett's test
    
```{R}
#Create box plots that show distribution of weight loss for each group
boxplot(mile_time ~ snack, xlab='Snack', ylab='Mile Time', data=data)
```
```{R}
#Create box plots that show distribution of weight loss for each group
bartlett.test(mile_time ~ snack, data=data)
```
   
- sd should not be more than 2X bigger in one group compared to another

---

### How to run a one-way ANOVA

One-way ANOVAs use the standard null/alternative hypothese. 

**Ho (null): ** the population means are equal

**Ha (alternative): ** at least one population mean in different from the rest

After running your analysis, your output will something like this:

![](/img/portfolio/anova_tablbe.png)

- SSR: regression sum of squares
- SSE: error sum of squares
- SST: total sum of squares (SST = SSR + SSE)
- dfr: regression degrees of freedom (dfr = k-1)
- dfe: error degrees of freedom (dfe = n-k)
- dft: total degrees of freedom (dft = n-1)
- k: total number of groups
- n: total observations
- MSTr: regression mean square (MSTr = SSR/dfr)
- MSE: error mean square (MSE = SSE/dfe)
- F: The F test statistic (F = MSR/MSE)
- p: The p-value that corresponds to Fdfr, dfe

If the p-value is less than 0.05 (or another chosen significance value) then we can reject the null hypothesis and conclude one of the population means is different from the rest. 

If and only if you conclude there is at least one difference in population means from the one-way ANOVA, you need to perform post hoc tests to figure out exactly WHICH population means are different from eachother. 

---

### One-way ANOVA walkthrough 

Back to our original example: snacks and running times. Say, for example, we want to find out which pre-workout snack lead to different mean mile times. For this example, we will be testing carrots, snickers, and bannans. Because there are millions of people around the world who workout everyday, it would be almost impossible to asses the effect of their pre-workout snack on their mile time, so we select a *random sample* of individuals who work out and give each of them one of the three pre-workout snacks, and record their mile time after they eat their respective snack. 

```{R}
#make this example reproducible
set.seed(0)

#create data frame
data <- data.frame(snack = rep(c("carrot", "snickers", "bannana"), each = 30),
                   mile_time = c(runif(30, 6, 7),
                                   runif(30, 4, 5),
                                   runif(30, 8, 12)))
head(data)
```
Now that we have our data, lets check our assumptions. 

```{R}
#load dplyr package
library(dplyr)

#find mean and standard deviation of weight loss for each treatment group
data %>%
  group_by(snack) %>%
  summarise(mean = mean(mile_time),
            sd = sd(mile_time))
```
```{R}
#create boxplots
boxplot(mile_time ~ snack,
data = data,
main = "Mile Time Distribution by Snack",
xlab = "Snack",
ylab = "Mile Time",
col = "steelblue",
border = "black")
```
```{R} 
# install.packages("ggplot2")
library(ggplot2)

# Basic density plot in ggplot2
cols <- c("#F76D5E", "#FFFFBF", "#72D8FF")

ggplot(data, aes(x = mile_time, fill = snack)) +
  geom_density(alpha = 0.7) + 
  scale_fill_manual(values = cols)

```
Here we can clearly see a difference in mile times between the groups. It also looks like the bananas snack group has a higher standard deviation compared to the other snacks. 

1. Check for independence. We used a randomized experiment design, so this assumption is met. 
2. Normality. The dependent variables are approximately normally distributed for each predictor variable. 
3. Equal Variance. The variance for each group appears to be equal. 
```{R}
plot(model)
```
The Residuals vs Fitted plot lets us check equal variance assumption. The residuals should be equally spread for each level of the fitted value, but the plot above shows the residuals are much more spread out for the higher values. Our equal variance assumption might be violated. To formally check for equal variance, lets run Levene's test. 

```{R}
#load car package
library(car)

#conduct Levene's Test for equality of variances
leveneTest(mile_time ~ snack, data = data)
```
Our p-value is <<0.05. This means we accept the null hypothesis that there is equal variance across the 3 programs... Great!

The QQplot lets us check normality. The standardized residuals should fall straight on the diagonal line, but the plot above shows fraying at the beginning and the end. Out normality assumption might be violated. We could attempt to transform the data in order to make it follow a 

Now, lets fit the one-way ANOVA model. 
Here we are using the R aov() function which takes the response variable parameter, the predictor variable parameter, and the data set. In our case, we are using mile_time as the response variable and snack as the predictor variable. 

```{R}
#fit the one-way ANOVA model
model <- aov(mile_time ~ snack, data = data)

#view the model output
summary(model)
```

The Pr( >F ) value in the output tells us there is a significantly different mean mile times that resulted from each of the snack choices! Great. Now to figure out exactly which means are significantly different, we need to run a post hoc test. 

To run a post-hoc test, we will use Tukey's test of multiple comparisons. 
```{R}
#perform Tukey's Test for multiple comparisons
TukeyHSD(model, conf.level=.95) 
```

All of the p-values in this output are << 0.05, so we reject the null that there is no difference between the groups. In the table above, we can see that there is a statistically significant difference between the mean mile time of each snack group!

### Report Results

This was always the most confusing part of statistical analysis for me- properly recording the test results in APA format. Below you will find a standard results report for a one-way ANOVA:

> A one-way ANOVA was performed to compare the effect of [independent variable] on [dependent variable]..
>
> A one-way ANOVA revealed that there [was or was not] a statistically significant difference in [dependent variable] between at least two groups (F(between groups df, within groups df) = [F-value], p = [p-value]).
>
> Tukey’s HSD Test for multiple comparisons found that the mean value of [dependent variable] was significantly different between [group name] and [group name] (p = [p-value], 95% C.I. = [lower, upper]).
>
>There was no statistically significant difference between [group name] and [group name] (p=[p-value]).

For our walkthrough example, this would be the proper format:

A one-way ANOVA was conducted to examine the effects of pre-workout snack on mile time (measured in minutes). There was a statistically significant difference between the effects of the three programs on weight loss (F(2, 87) = 575.6, p = <2e-16). Tukey’s HSD post hoc tests were carried out.

The mean mile time for participants who ate carrots is significantly less than than the mean mile time for participants who ate a bannana (p < 0.0001).

The mean mile time for participants who ate snickers is significantly lower than the mean mile time for participants who ate a bannana (p < 0.0001).

The mean mile time for participants who ate snickers is significantly lower than the mean mile time for participants who ate a carrot (p < 0.0001).







