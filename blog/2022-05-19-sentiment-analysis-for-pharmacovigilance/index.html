<!DOCTYPE html>
<html lang="en-us">
<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<title>Zora Zorkiƒá</title>
<meta name="description" content="The personal website of Zora Zorkiƒá">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="https://hzorkic.github.io/css/bootstrap.min.css">
<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Roboto:400,300,700,400italic">
<link rel="stylesheet" href="https://hzorkic.github.io/css/font-awesome.min.css">
<link rel="stylesheet" href="https://hzorkic.github.io/css/owl.carousel.css">
<link rel="stylesheet" href="https://hzorkic.github.io/css/owl.theme.css">


  <link href="https://hzorkic.github.io/css/style.default.css" rel="stylesheet" id="theme-stylesheet">

 

  
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  


<link href="https://hzorkic.github.io/css/custom.css" rel="stylesheet">
<link rel="shortcut icon" href="https://hzorkic.github.io/img/favicon.png">



 
<script src="//ajax.googleapis.com/ajax/libs/jquery/2.2.1/jquery.min.js" ></script> 

<script type="text/javascript" src="js/bigfoot.js"></script> 
<link rel="stylesheet" type="text/css" href="css/bigfoot.css"> 

<script type="text/javascript"> $.bigfoot(); </script> 
</head>
<body>
  <div id="all">
      <div class="container-fluid">
          <div class="row row-offcanvas row-offcanvas-left">
              <div id="sidebar" class="col-xs-6 col-sm-4 col-md-3 sidebar-offcanvas">
  <div class="sidebar-content" >
    
    <h1 class="sidebar-heading">
      <div class="hidden-xs"><img style="max-width: 70%; margin-bottom: 15px;  height: auto; border: 2px black solid; border-radius: 190px; max-height: 300px" src="/img/prof.png" alt=""></div>
      
      <a href="https://hzorkic.github.io/">
        
        <img src="https://see.fontimg.com/api/renderfont4/GOZEP/eyJyIjoiZnMiLCJoIjo2NSwidyI6MTAwMCwiZnMiOjY1LCJmZ2MiOiIjMDAwMDAwIiwiYmdjIjoiI0ZGRkZGRiIsInQiOjF9/em9yYSB6b3JraWM/sizelademo-regular.png" alt="Prehistoric fonts" style="height: auto; max-height: 80%; max-width: 100%; margin-bottom: 20px;">
      </a>
    </h1>
    
    
      <p class="sidebar-p" style="margin-bottom: 2px; ">Data Scientist.</p>
    
      <p class="sidebar-p" style="margin-bottom: 2px; ">UX Researcher.</p>
    
    
    
      <p class="sidebar-p" style="margin-top: 20px; "\>üìç Somewhere between Austin and San Diego </p>
    
    
   
    <ul class="sidebar-menu" style="margin-top: 20px; ">
      
        <li><a href="https://hzorkic.github.io/about/">About</a></li>
      
        <li><a href="https://hzorkic.github.io/blog/">Blog</a></li>
      
        <li><a href="https://docs.google.com/document/d/1kj4knE2wdZdFEqjAO-J8EwKpLbXFVES-eprmV8g3lqs/edit?usp=sharing">CV</a></li>
      
      
      
    </ul>
    <p class="social">
  
  
  
  
  
  <a href="mailto:hayley.zorkic@gmail.com" data-animate-hover="pulse" class="email" title="E-mail">
    <i class="fa fa-envelope"></i>
  </a>
  
  
  <a href="https://www.linkedin.com/in/hayley-zorkic" data-animate-hover="pulse" class="external" title="LinkedIn" rel="me">
    <i class="fa fa-linkedin"></i>
  </a>
  
  
  
  <a href="https://github.com/hzorkic" data-animate-hover="pulse" class="external" title="GitHub" rel="me">
    <i class="fa fa-github"></i>
  </a>
  
  
  
  
</p>

      <div class="copyright" style="font-size: 2px;">
        
      </div>
    
    
    

    
  </div>
</div>

              
<div class="col-xs-12 col-sm-8 col-md-9 content-column white-background">
  <div class="small-navbar visible-xs">
  <button type="button" data-toggle="offcanvas" class="btn btn-ghost">
    <i class="fa fa-bars"></i>
  </button>
  <h1 class="small-navbar-heading">
    <a href="https://hzorkic.github.io/">
      <img src="https://see.fontimg.com/api/renderfont4/GOZEP/eyJyIjoiZnMiLCJoIjo2NSwidyI6MTAwMCwiZnMiOjY1LCJmZ2MiOiIjMDAwMDAwIiwiYmdjIjoiI0ZGRkZGRiIsInQiOjF9/em9yYSB6b3JraWM/sizelademo-regular.png"
      style="max-height:30px;">
    </a>
  </h1>
</div>

  <div class="row">
    <div class="col-lg-8">
      <div class="content-column-content">
         <h1>Sentiment Analysis for Post-Approval Birth Control Review Pharmacovigilance</h1>
         <p><img src="/img/portfolio/contraceptives.png" alt=""></p>
<p><img src="/img/portfolio/wordcloud_pos_unigram.png" alt=""></p>
<h2 id="1-introduction">1. Introduction</h2>
<p>While pharmaceutical birth control continues to be the most popular method of contraceptive in the United States, the proliferation of different formulations of these methods can make decisions regarding which to use difficult for individual persons (Kavanaugh &amp; Jerman, 2018). Additionally, research has shown that there may be a tendency for providers to diminish or avoid disclosing adverse side effects of contraceptives, further hindering a comprehensive understanding of its efficacy (Stevens, 2018).</p>
<p>Pharmacovigilance (PV) is the field concerned with the collection, detection, assessment, monitoring, and prevention of adverse effects of drugs. Typically, adverse effects are reported in formal clinical settings or outlined in literature, however there is a wealth of knowledge that could be extracted from informal settings. In the context of an increase in internet usage by all age groups in general‚Äìas well as specifically in younger adults using social media to report and seek health information‚Äìit follows that individuals interested in learning more about pharmaceutical contraceptive methods may increasingly turn to the internet for information as well as to report their experiences (Wartella et al., 2016). Tweets, reddit posts, and drug review websites may provide valuable insight into the nature of an individual‚Äôs experience with a particular pharmaceutical, as well as indicate if negative side effects are more widespread than originally indicated by clinical trials. By combining informal drug review platforms and machine learning methods, biotechnological, biopharmaceutical, and regulatory agencies have a unique opportunity to modernize pharmacovigilance in order to see how drugs are being received in a real-world context, addressing potential bias inherent in a formal trial setting.</p>
<p>In this project, we are interested in building sentiment analysis models that can help analyze the sentiment of contraceptives. In particular we would like to identify which models perform best for this task as well as if data trained on reviews from years prior are applicable to modern reviews.</p>
<h2 id="2-data">2. Data</h2>
<p>Our data consists of birth control drug reviews from a dataset in the UCI Machine Learning Repository. The dataset provides short-response patient reviews on specific drugs as well as a scaled patient rating (1-10) reflecting overall patient satisfaction with the drug. The authors obtained the data by crawling online pharmaceutical review sites (Gr√§√üer et al., 2018). The dataset includes 215,063 reviews in total, 28,930 of which are for birth control. Our original intention was to train our models using the UCI dataset and predict sentimentality for social media posts (e.g. tweets, Reddit posts) regarding experiences using pharmaceutical birth control methods; however, the short responses in the training data were too dissimilar to short-responses that could be gathered from tweets and Reddit posts. In order to generate new data congruent to the original UCI dataset, we scraped reviews of pharmaceutical birth control from Drugs.com (one of the sources of the UCI data) from the year 2018 onward using the ‚Äòrequests‚Äô and ‚ÄòBeautifulSoup‚Äô python packages (Prewitt &amp; Larson, 2011; Richardson, 2021).</p>
<p><img src="/img/portfolio/drugs_com.png" alt=""></p>
<p>We trained our models on the UCI data, which includes all birth control reviews from Drugs.com and Druglib.com written before 2017. Given that the ways in which individuals communicate online can shift rapidly in a relatively short time span, the age of the training dataset for a model must be considered when predicting outcomes for recent posts. Determining whether a model based on UCI‚Äôs dataset remains accurate for more recent drug reviews, despite the time difference, would provide initial proof of concept of its usefulness in evaluating other potential datasets.</p>
<h2 id="3-methodology">3. Methodology</h2>
<p><strong>3.1 Preprocessing &amp; Models</strong></p>
<p>The reviews in the UCI dataset were filtered to only include those who listed ‚Äúbirth control‚Äù as the treating condition. Reviews for implantable, oral, or injectable birth control pharmaceuticals which had not been labeled with a condition but upon review of the text were determined to be prescribed for contraceptive use (i.e. not for treatment of acne or irregular bleeding) were also included. The final dataset included only the review text and the scaled rating of the drug, which was compressed to a binary category (i.e. 1-5 was coded as 0 indicating a negative review, 6-10 was coded as 1 indicating a positive review).</p>
<p>There are several models that can be used for sentiment analysis. We selected models that were likely to be relevant for our specific dataset based on previous work with the same review set (Vijayaraghavan &amp; Basu, 2020). Initially, the following models were coded and trained: Naive Bayes, Logistic Regression, Random Forest, and k-Nearest Neighbors (with k=1,3,5,7,10). The kNN models displayed a dramatic decrease in performance relative to the other models and repeatedly timed out in testing with bigram data, thus we elected to drop this model. A Linear Support Vector Classification (Linear SVC) model was instead implemented as it is significantly less computationally expensive and considered a front-line model for text classification (Muller &amp; Collier, 2015). The Linear SVC model was also trained with the unigram data prior to training with bigrams along with the rest of the models.</p>
<p>Initially, review text was tokenized as unigrams. Examination of models based on unigrams revealed that many of the same words were appearing as the most frequent words in both the positive and negative categories. Based on further investigation of false negatives and false positives, as well as expert recommendation (Dr. Li), it was determined training models with more context might help differentiate reviews containing negation (e.g. ‚Äúnot good‚Äù). Thus, review text was also tokenized into bigrams prior to training and vectorized using CountVectorizer (sklearn) for Naive Bayes and Logistic Regression and TFIDVectorizer was used for the Random Forest and the Linear Support Vector Classification models.</p>
<h2 id="4-results">4. Results</h2>
<p><img src="/img/portfolio/pharm_results_table.png" alt=""></p>
<p>Initial tests were run by training our models on the UCI dataset with a 25/75 test/train split. Results were evaluated using accuracy, precision, recall, F1 score, and area under the receiver operating characteristic (ROC) curve. For detailed results of performance with test data, see Figure 1. Additionally, we provide AUC-ROC plots and confusion matrix visualizations for each of the top-performing models.</p>
<p><strong>Test Data Performance with Unigrams</strong></p>
<p>For models trained with unigrams, overall performance was good. The Random Forest model performed the best according to evaluation metrics (accuracy 87.42, precision 87.74, recall 86.58, F1 86.99, and area under the ROC curve of 0.8658, Figure 2). The next best unigram models were Logistic Regression (accuracy 85.23, precision 85.03, recall 84.76, F1 84.88, and area under the ROC curve 0.8476) followed closely by Linear SVC (accuracy 85.01, precision 84.78, recall 84.57, F1 84.67, and area under the ROC curve 0.8457).</p>
<p><img src="/img/portfolio/pharm_test_unigrams.png" alt=""></p>
<p>We investigated the top performing algorithm further. The Random Forest model made mistakes in classifying reviews such as ‚Äú9 rating based entirely how easy it was to have placed and its efficacy but I had the most severe side effects you can imagine‚Ä¶I became moody and extremely depressed I could barely function‚Ä¶‚Äù as negative. This review is indicative of a pattern of certain reviews in the dataset where the overall rating was based on one specific aspect of the individual‚Äôs experience in the context of a generally more negatively-worded review. Other types of reviews the model struggled with also had mixed language, discussing both downsides and upsides of different methods (e.g. ‚ÄúBrilliant. Now it just needs time. Mine was awful at the start: headaches and stomachache and arm pain and bleeding. But 3 months later I have nothing at all it‚Äôs worth that wait‚Äù). Many of the misclassified reviews, upon examination of the original uncompressed ratings, were revealed to sit near the boundary of where we artificially categorized positive and negative reviews for our purposes (i.e. ratings of 5-6).</p>
<p>The Random Forest model also struggled with reviews such as ‚ÄúThe Nuvaring is a great contraceptive if you don‚Äôt like being yourself. My mood swings were unpredictable and nasty‚Ä¶I lost my sex drive almost completely and seven months later I am still struggling to get my sex drive back‚Ä¶I would not recommend this to anyone.‚Äù This example may be difficult to classify with a unigram model as it contains a negation (i.e. ‚Äúdon‚Äôt like‚Äù ‚Äúwould not recommend‚Äù), as well as sarcasm, which was noted in a number of other false positives.</p>
<p><strong>Test Data Performance with Bigrams</strong></p>
<p>Classification of reviews tokenized into bigrams improved compared to unigrams with for the Naive Bayes, Logistic Regression, and Linear SVC models, with the best performance from the Logistic Regression model (accuracy 86.11, precision 86.00, recall 85.58, F1 85.76, and area under the ROC curve 0.8558, Figure 3).</p>
<p><img src="/img/portfolio/pharm_test_bigram.png" alt=""></p>
<p>The Logistic Regression model struggled with reviews that mentioned previous negative experiences with birth control contrasted with a current positive experience‚Äìmistakenly classifying these as negative (e.g. ‚ÄúI love it not having to take a pill everyday. It‚Äôs amazing so far. I‚Äôve been on it for 3 weeks now‚Ä¶I hated take the pill and yaz and trisprintec made me so depressed moody and I had no sex drive‚Ä¶my sex drive is getting better so wish me luck‚Äù). The other models similarly had trouble classifying these types of reviews, indicating that this review structure is likely difficult to decipher in a classification task without taking a large amount of context into consideration.
Similar to the models trained on unigrams, the Logistic Regression model trained on bigrams also struggled with reviews that fell close to our artificial categorical boundary in rating.</p>
<p>The Logistic Regression model also made misclassifications of negative reviews that contain clear negative language (e.g. ‚ÄúI wish I never took this pill‚Ä¶I‚Äôm an emotional person but this pill turned me into a monster. I have never been so sad in my entire life. I had thoughts of harming myself and was constantly causing arguments with my boyfriend‚Ä¶‚Äù). It‚Äôs unclear what features of reviews like these might be driving the model to classify them as positive. This type of misclassification might point to a more general issue with the structure of reviews where negative symptoms or experiences are mentioned alongside or in contrast to positive experiences, which was common in the dataset. These types of reviews may have produced some disadvantageous methods of determining sentiment, where clearly negative or positive words could not be relied upon for classification.</p>
<p><strong>Performance on Scraped Data with Unigrams</strong></p>
<p>The Naive Bayes, Logistic Regression, Random Forest, and Linear SVC models were used to predict the polarity of newly scraped reviews based on both unigrams and bigrams. As stated in prior sections, we scraped reviews and ratings data from Drugs.com from 2021 and above using the Beautiful Soup package. Because we were able to also extract data from one of the sites that the original data came from, we were able to see how the models which were trained on data from before 2018 performs on modern data. For details of model performance, see Figure 1.</p>
<p><img src="/img/portfolio/pharm_scrape_unigram.png" alt=""></p>
<p>For classification of newly scraped reviews using unigrams, the Logistic Regression model performed the best (accuracy 79.97, precision 80.11, recall 79.87, F1 79.90, area under the ROC curve 0.7987, Figure 4). This result indicates that the Random Forest model with unigrams may have been overfitted with the training data, and so with the introduction of a new dataset, model performance fell. The Logistic Regression model performed nearly as well as the Random Forest model in training, and may be more robust to differences in datasets.</p>
<p><strong>Performance on Scraped Data with Bigrams</strong></p>
<p>With tokenization into bigrams, the Naive Bayes model performed the best (accuracy 78.65, precision 78.96, recall 78.50, F1 78.52, area under the ROC curve 0.7849, Figure 5). Unlike tests with the original dataset, implementation of bigrams produced a decline in performance for all models in classifying the scraped reviews. While our hypothesis was that additional context would aid in classification of these reviews, perhaps longer n-grams would need to be used in order to achieve improved performance for these models.</p>
<p><img src="/img/portfolio/pharm_scrape_bigram.png" alt=""></p>
<h2 id="5-conclusion">5. Conclusion</h2>
<p>We implemented the Logistic Regression, Naive Bayes, Random Forest, and SVM algorithms on a UCI ML drug review dataset in order to classify the sentiment of post-approval birth control reviews from Drugs.com. In general, the Logistic Regression and SVM models performed the best on test data (development), as well as newly scraped data for both unigrams and bigrams. Because the sentiment analysis of the old data performed well in development tests and newly-scraped data tests, our results indicate that overall, sentiment analysis models trained on older reviews of birth control options on pharmaceutical review sites can provide relatively high levels of accuracy in classifying the sentiment of more recent reviews.</p>
<p>While our project outlines a model to predict if reviews are ‚Äúgood‚Äù or ‚Äúbad‚Äù, we are limited in the application of our work without further development. Future research should incorporate a way to identify which specific drugs are receiving the best and worst reviews. Additionally, we encourage the development of models that can be used on even less formal text than reviews from Drugs.com such as posts on Twitter or Reddit. Incorporating these into the pipeline would allow for a more comprehensive model as well as allow those in PV to identify certain drugs of concern based on public sentiment.</p>
<h2 id="6-source-code">6. Source Code</h2>
<p><a href="https://github.com/hzorkic/Pharmacovigilance_Sentiment_Analysis">https://github.com/hzorkic/Pharmacovigilance_Sentiment_Analysis</a></p>
<h2 id="7-references">7. References</h2>
<ul>
<li>12 twitter sentiment analysis algorithms compared. (2021, June 15). AI Perspectives. Retrieved March 25, 2022, from <a href="https://www.aiperspectives.com/twitter-sentiment-analysis/">https://www.aiperspectives.com/twitter-sentiment-analysis/</a></li>
<li>Bird, S., Klein, E., &amp; Loper, E. (2009). Natural language processing with Python: analyzing text with the natural language toolkit. O‚ÄôReilly Media, Inc. <a href="https://www.nltk.org/index.html">https://www.nltk.org/index.html</a></li>
<li>Chou, S. Y. (2020, April 25) Compute the AUC of Precision-Recall Curve. Sin-Yi Chou. <a href="https://sinyi-chou.github.io/python-sklearn-precision-recall/">https://sinyi-chou.github.io/python-sklearn-precision-recall/</a></li>
<li>Gr√§√üer, F., Kallumadi, S., Malberg, H., &amp; Zaunseder, S. (2018, April 23-26). Aspect-based sentiment analysis of drug reviews applying crossdomain and cross-data learning. International Conference on Digital Health, New York, USA.</li>
<li>Hunter, J. D. (2007). Matplotlib: A 2D graphics environment. Computing in Science &amp; Engineering 9(3), 90-95.</li>
<li>Kavanaugh, M. L. &amp; Jerman, J. (2018) Contraceptive method use in the United States: trends and characteristics between 2008, 2012, and 2014. Contraception, 97(1), 14-21. 10.1016/j.contraception.2017.10.003</li>
<li>Mueller, A. (2020). WordCloud for Python (1.8.1). GitHub. <a href="https://amueller.github.io/word_cloud/">https://amueller.github.io/word_cloud/</a></li>
<li>Mullen, T. &amp; Collier, N. (2004, July 25-26). Sentiment Analysis using Support Vector Machines with Diverse Information Sources. Conference on Empirical Methods in Natural Language Processing, Barcelona, Spain.</li>
<li>Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J., Passos, A., Cournapeau, D., Brucher, M., Perrot, M., &amp; Duchesnay, E. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825-2830.</li>
<li>Prewitt, N., Larson, S. M. (2011). Requests (2.27.1). GitHub. <a href="https://docs.python-requests.org/en/latest/">https://docs.python-requests.org/en/latest/</a></li>
<li>Pushshift. (2019). Pushshift Reddit API. GitHub. <a href="https://github.com/pushshift/api">https://github.com/pushshift/api</a></li>
<li>Richardson, L. (2021) Beautiful Soup (4.11.1). Crummy. <a href="https://www.crummy.com/software/BeautifulSoup/">https://www.crummy.com/software/BeautifulSoup/</a></li>
<li>Roesslein, J. (2009). Tweepy (4.9.0). Tweepy. <a href="https://www.tweepy.org/">https://www.tweepy.org/</a></li>
<li>Romer, D. (2016). Adolescents in the digital age: Effects on health and development. Media Communication, 4(3). 10.17645/mac.v4i3.658</li>
<li>Stevens, L. M. (2018). ‚ÄúWe have to be mythbusters‚Äù: Clinician attitudes about the legitimacy of patient concerns and dissatisfaction with contraception. Social Science &amp; Medicine, 212, 145-152.</li>
<li>Symeonidis, S. (2018, March 26). 5 things you need to know about sentiment analysis and classification. KDnuggets. <a href="https://www.kdnuggets.com/2018/03/5-things-sentiment-analysis-classification.html">https://www.kdnuggets.com/2018/03/5-things-sentiment-analysis-classification.html</a></li>
<li>Twitter. (2022). Twitter API for academic research. Twitter. <a href="https://developer.twitter.com/">https://developer.twitter.com/</a></li>
<li>Vijayaraghavan, S., &amp; Basu, D. (2020). Sentiment analysis in drug reviews using supervised
machine learning algorithms. ArXiv abs/2003, 11643.</li>
<li>Wartella, E., Rideout, V., Montague, H., Beaudoin-Ryan, L., &amp; Lauricella, A. (2016) Teens, Health, and Technology: A National Survey. Media and Communication 4(3). 10.17645/mac.v4i3.515</li>
<li>Wickham, H. (2020). httr: Tools for Working with URLs and HTTP (1.4.2). RStudio. <a href="https://cran.r-project.org/web/packages/httr/index.html?Author=Andrew%2520Pitre&amp;Preview=true">https://cran.r-project.org/web/packages/httr/index.html?Author=Andrew%2520Pitre&amp;Preview=true</a></li>
<li>Zach. (2021, April 6) How to Plot an ROC Curve in Python (Step-by-Step). Statology. <a href="https://www.statology.org/plot-roc-curve-python/">https://www.statology.org/plot-roc-curve-python/</a></li>
</ul>
<h2 id="contributions">Contributions</h2>
<p><strong>Hayley Zorkic</strong> coded the models and evaluation methods, scraped and prepared the recent drug review dataset, and co-wrote the project paper.</p>
<p><strong>Karinne Berstis</strong> cleaned the UCI dataset, optimized, evaluated, and visualized results, and co-wrote the project paper.</p>

         
      </div>
    </div>
  </div>
</div>

          </div>
      </div>
  </div>
  <script src="https://hzorkic.github.io/js/jquery.min.js"></script>
<script src="https://hzorkic.github.io/js/bootstrap.min.js"></script>
<script src="https://hzorkic.github.io/js/jquery.cookie.js"> </script>
<script src="https://hzorkic.github.io/js/ekko-lightbox.js"></script>
<script src="https://hzorkic.github.io/js/jquery.scrollTo.min.js"></script>
<script src="https://hzorkic.github.io/js/masonry.pkgd.min.js"></script>
<script src="https://hzorkic.github.io/js/imagesloaded.pkgd.min.js"></script>
<script src="https://hzorkic.github.io/js/owl.carousel.min.js"></script>
<script src="https://hzorkic.github.io/js/front.js"></script>



</body>
</html>
